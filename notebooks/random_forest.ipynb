{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest â€” Standalone Notebook (Excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains **one model** on your Excel dataset. Set CONFIG below and Run All."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Excel load failed, trying CSV fallback...\n",
      "[INFO] Loaded CSV fallback with encoding=utf-8\n"
     ]
    }
   ],
   "source": [
    "# ---- CONFIG: EDIT THESE ----\n",
    "DATASET_XLSX_PATH = '/Users/srilalitha_gunturu@optum.com/Downloads/Customer Churn.csv'   # e.g., data/Heart_Disease.xlsx\n",
    "TARGET_COLUMN     = 'Churn'              # e.g., 'target'\n",
    "RANDOM_STATE      = 42\n",
    "TEST_SIZE         = 0.2\n",
    "# ----------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Excel loader with CSV fallback\n",
    "_df = None\n",
    "try:\n",
    "    _df = pd.read_excel(DATASET_XLSX_PATH, engine='openpyxl')\n",
    "    print(f\"[INFO] Loaded Excel file: {DATASET_XLSX_PATH}\")\n",
    "except Exception as _e:\n",
    "    print(\"[WARN] Excel load failed, trying CSV fallback...\")\n",
    "    for _enc in ['utf-8','utf-8-sig','latin-1','cp1252']:\n",
    "        try:\n",
    "            _df = pd.read_csv(DATASET_XLSX_PATH, encoding=_enc)\n",
    "            print(f\"[INFO] Loaded CSV fallback with encoding={_enc}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _df is None:\n",
    "        raise ValueError(\"Could not load dataset. Check path/format.\")\n",
    "\n",
    "df = _df\n",
    "assert TARGET_COLUMN in df.columns, f\"Target '{TARGET_COLUMN}' not in columns: {df.columns.tolist()}\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[TARGET_COLUMN])\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numeric_cols     = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# OHE compatibility\n",
    "_ohe_sparse = {'handle_unknown':'ignore'}\n",
    "_ohe_dense  = {'handle_unknown':'ignore'}\n",
    "_maj,_min = [int(v) for v in sklearn.__version__.split('.')[:2]]\n",
    "if (_maj,_min) >= (1,2):\n",
    "    _ohe_sparse['sparse_output'] = True\n",
    "    _ohe_dense['sparse_output']  = False\n",
    "else:\n",
    "    _ohe_sparse['sparse'] = True\n",
    "    _ohe_dense['sparse']  = False\n",
    "\n",
    "preprocessor_sparse = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(**_ohe_sparse), categorical_cols),\n",
    "    ('num', 'passthrough', numeric_cols)\n",
    "])\n",
    "\n",
    "preprocessor_dense = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(**_ohe_dense), categorical_cols),\n",
    "    ('num', 'passthrough', numeric_cols)\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e334d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def safe_auc(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Returns AUC or None if it cannot be computed.\n",
    "    - Handles binary (uses proba[:,1]) and multiclass (OvR, weighted).\n",
    "    - Returns None if y_true has a single class or probabilities are missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return None\n",
    "        if y_proba is None:\n",
    "            return None\n",
    "\n",
    "        y_proba = np.asarray(y_proba)\n",
    "        if y_proba.ndim == 1:\n",
    "            # Already the positive-class probability\n",
    "            return float(roc_auc_score(y_true, y_proba))\n",
    "        elif y_proba.ndim == 2:\n",
    "            if y_proba.shape[1] == 2:\n",
    "                # Probability of positive class\n",
    "                return float(roc_auc_score(y_true, y_proba[:, 1]))\n",
    "            else:\n",
    "                # Multiclass OvR weighted\n",
    "                return float(roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted'))\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor_sparse),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE))\n",
    "])\n",
    "clf = pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9651, 'auc': 0.9877, 'precision': 0.9645, 'recall': 0.9651, 'f1': 0.9645, 'mcc': 0.8648}\n",
      "Confusion Matrix: [[524   7]\n",
      " [ 15  84]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       531\n",
      "           1       0.92      0.85      0.88        99\n",
      "\n",
      "    accuracy                           0.97       630\n",
      "   macro avg       0.95      0.92      0.93       630\n",
      "weighted avg       0.96      0.97      0.96       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "proba = clf.predict_proba(X_test) if hasattr(clf, 'predict_proba') else None\n",
    "pred  = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef, confusion_matrix, classification_report)\n",
    "\n",
    "# Predictions and probabilities\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = None\n",
    "if hasattr(clf.named_steps['clf'], 'predict_proba'):\n",
    "    try:\n",
    "        y_proba = clf.predict_proba(X_test)\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "prec= precision_score(y_test, pred, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_test, pred, average='weighted', zero_division=0)\n",
    "f1  = f1_score(y_test, pred, average='weighted', zero_division=0)\n",
    "mcc = matthews_corrcoef(y_test, pred)\n",
    "cm  = confusion_matrix(y_test, pred)\n",
    "rep = classification_report(y_test, pred, output_dict=False, zero_division=0)\n",
    "auc = safe_auc(y_test,y_proba)\n",
    "\n",
    "print({'accuracy': round(acc,4), 'auc': None if auc is None else round(auc,4),\n",
    "       'precision': round(prec,4), 'recall': round(rec,4), 'f1': round(f1,4), 'mcc': round(mcc,4)})\n",
    "print('Confusion Matrix:', cm)\n",
    "print('Classification Report:')\n",
    "print(rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
